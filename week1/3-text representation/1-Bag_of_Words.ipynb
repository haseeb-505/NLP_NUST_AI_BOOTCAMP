{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMoADcrhJP2H"
      },
      "source": [
        "## Bag of Words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BQgGeqjyexf",
        "outputId": "1869ef7f-341a-42cf-d395-651a0d6f6d87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==0.21.3\n",
            "  Using cached scikit_learn-0.21.3-cp36-cp36m-win_amd64.whl (5.9 MB)\n",
            "Collecting scipy>=0.17.0\n",
            "  Using cached scipy-1.5.4-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
            "Collecting joblib>=0.11\n",
            "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
            "Collecting numpy>=1.11.0\n",
            "  Using cached numpy-1.19.5-cp36-cp36m-win_amd64.whl (13.2 MB)\n",
            "Installing collected packages: numpy, scipy, joblib, scikit-learn\n",
            "Successfully installed joblib-1.0.1 numpy-1.19.5 scikit-learn-0.21.3 scipy-1.5.4\n"
          ]
        }
      ],
      "source": [
        "# To install only the requirements of this notebook, uncomment the lines below and run this cell\n",
        "\n",
        "# ===========================\n",
        "\n",
        "!pip install scikit-learn==0.21.3\n",
        "\n",
        "# ==========================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2Pa4uTCyexh"
      },
      "outputs": [],
      "source": [
        "# To install the requirements for the entire chapter, uncomment the lines below and run this cell\n",
        "\n",
        "# ===========================\n",
        "\n",
        "# try :\n",
        "#     import google.colab\n",
        "#     !curl https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch3/ch3-requirements.txt | xargs -n 1 -L 1 pip install\n",
        "# except ModuleNotFoundError :\n",
        "#     !pip install -r \"ch3-requirements.txt\"\n",
        "\n",
        "# ==========================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhnX4sORJP2J",
        "outputId": "29d4b1d0-5117-4508-bb2c-b4ed584fa196"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"] #Same as the earlier notebook\n",
        "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
        "processed_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEm3kuokJP2N"
      },
      "source": [
        "Now, let's do the main task of finding bag of words representation. We will use CountVectorizer from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbCdQVWQJP2O",
        "outputId": "338d3f76-81da-4987-9983-24270aa1fa9d",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our corpus:  ['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']\n",
            "Our vocabulary:  {'dog': 1, 'bites': 0, 'man': 4, 'eats': 2, 'meat': 5, 'food': 3}\n",
            "BoW representation for 'dog bites man':  [[1 1 0 0 1 0]]\n",
            "BoW representation for 'man bites dog:  [[1 1 0 0 1 0]]\n",
            "Bow representation for 'dog and dog are friends': [[0 2 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#look at the documents list\n",
        "print(\"Our corpus: \", processed_docs)\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "#Build a BOW representation for the corpus\n",
        "bow_rep = count_vect.fit_transform(processed_docs)\n",
        "\n",
        "#Look at the vocabulary mapping\n",
        "print(\"Our vocabulary: \", count_vect.vocabulary_)\n",
        "\n",
        "#see the BOW rep for first 2 documents\n",
        "print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray())\n",
        "print(\"BoW representation for 'man bites dog: \",bow_rep[1].toarray())\n",
        "\n",
        "#Get the representation using this vocabulary, for a new text\n",
        "temp = count_vect.transform([\"dog and dog are friends\"])\n",
        "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVUOxhBgyexj"
      },
      "source": [
        "In the above code, we represented the text considering the frequency of words into account. However, sometimes, we don't care about frequency much, but only want to know whether a word appeared in a text or not. That is, each document is represented as a vector of 0s and 1s. We will use the option binary=True in CountVectorizer for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvFoqDRAJP2Q",
        "outputId": "df7e0194-d541-4e68-968e-00deee47f89f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bow representation for 'dog and dog are friends': [[0 1 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "#BoW with binary vectors\n",
        "count_vect = CountVectorizer(binary=True)\n",
        "count_vect.fit(processed_docs)\n",
        "temp = count_vect.transform([\"dog and dog are friends\"])\n",
        "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}